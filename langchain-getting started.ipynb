{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c943bc4-4abd-4b4b-9a26-8108860c4df2",
   "metadata": {},
   "source": [
    "## Setting up langchain \n",
    "\n",
    "We are going to be using Gemini models for the basic setup and so follow the below steps to setup -\n",
    "Install langchain \n",
    "```\n",
    "pip install -qU \"langchain[google-genai]\"\n",
    "```\n",
    "Generate the Google api key in order to use the gemini models. The free tier plan still gives 10 Requests per minute for free and 500 requests per day for free for Gemini 2.5-Flash as shown [here](https://ai.google.dev/gemini-api/docs/pricing)\n",
    "For generating the key, visit [this link](https://aistudio.google.com/app/apikey?). On the top click Get API Key. This will generate the api key which can be added to the bash file or can be fed when prompted with getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aeacc9",
   "metadata": {},
   "source": [
    "## Testing the base setup for langchain \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84e7b902-8dde-46bf-9a52-2cad613493b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I am doing well, thank you for asking! How are you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--5acb0009-e76d-4b4f-bdd8-24d874fdcbc6-0', usage_metadata={'input_tokens': 6, 'output_tokens': 16, 'total_tokens': 22, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "\n",
    "model = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")\n",
    "\n",
    "model.invoke(\"Hi, How are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9c9432e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 is bigger than 0.\n",
      "Please provide me with the numbers you want me to compare and then multiply the bigger one by 3.\n"
     ]
    }
   ],
   "source": [
    "resp = model.invoke(\"What is bigger? 2 or 0\")\n",
    "print(resp.content)\n",
    "print(model.invoke(\"Multiply the bigger number by 3\").content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a355288b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
